{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wordform\n",
    "import sys\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.models.rnn.translate import data_utils\n",
    "\n",
    "_DIGIT_RE = re.compile(r\"\\d\")\n",
    "_PAD = \"_PAD\"\n",
    "_GO = \"_GO\"\n",
    "_EOS = \"_EOS\"\n",
    "_UNK = \"_UNK\"\n",
    "_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n",
    "\n",
    "PAD_ID = 0\n",
    "GO_ID = 1\n",
    "EOS_ID = 2\n",
    "UNK_ID = 3\n",
    "\n",
    "sys.argv.extend([\"--train_dir=/data/korpora_train_1\",\n",
    "                \"--data_dir=/data/korpora\",\n",
    "                \"--size=1024\",\n",
    "                \"--learning_rate=1.0\",\n",
    "                \"--learning_rate_decay_factor=0.95\",\n",
    "                \"--num_layers=2\",\n",
    "                \"--vocab_size=3200\",\n",
    "                \"--steps_per_checkpoint=100\"])\n",
    "\n",
    "#wordform.log_data(1,2,3,4,5)\n",
    "#wordform.log_data(2,2,3,4,5)\n",
    "#data_dir = \"/data/korpora\"\n",
    "#_,_,input_dev,target_dev,_,_ = wordform.prepare_korpora_data(\"/data/korpora\", 1000)\n",
    "#target_data_path = os.path.join(data_dir,\n",
    "#                                 \"korpora_train.target\")\n",
    "#target_vocab_path = os.path.join(data_dir,\n",
    "#                                 \"vocab%d.target.test\" % 1000)\n",
    "#data_utils.create_vocabulary(target_vocab_path, target_data_path, 1000, wordform.char_tokenizer)\n",
    "#tv, rev_target_vocab = data_utils.initialize_vocabulary(target_vocab_path)\n",
    "#for r in rev_target_vocab[:20]:\n",
    "#    print(r, [r])\n",
    "#print(data_utils.sentence_to_token_ids(\"Grollen\", tv, wordform.bigram_tokenizer))\n",
    "#print wordform.bigram_tokenizer()\n",
    "#print([w for w in \"Geißel\".decode(\"utf-8\")])\n",
    "#print([\"Geißel\".decode(\"utf-8\")])\n",
    "\n",
    "\n",
    "#print(wordform.calc_buckects_scale([1000,2000,1000,3000]))\n",
    "#wordform._buckets_loss = [0.000869942, 0.0511547, 0.2372, 1.22821]\n",
    "#print(wordform.calc_buckects_scale([1000,2000,1000,3000]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = wordform.create_model(sess, False)\n",
    "break\n",
    "with tf.Session() as sess:\n",
    "    # Create model and load parameters.\n",
    "    model = wordform.create_model(sess, True)\n",
    "    dev_set = wordform.read_data(input_dev, target_dev)\n",
    "    eval_datas = wordform.evaluate_valid(model, sess, dev_set, 1)\n",
    "    hits = np.zeros(len(eval_datas))\n",
    "    for i in range(len(eval_datas)):\n",
    "        hits[i] = 1 if eval_datas[i][1][1:eval_datas[i][1].rindex(\".\")] == eval_datas[i][2] else 0\n",
    "        if not hits[i]:\n",
    "            print(\"wrong: \", eval_datas[i])\n",
    "    accuracy = sum(hits)/len(eval_datas)\n",
    "    print(\"%d datas, accuracy %.5f\" % (len(eval_datas), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"#abc.\"[1:-1] == \"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"/\" in \"http://www.spiegel.de/kultur/gesellschaft/china \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(\"aa\".find(\"b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.gfile.GFile(\"/data/korpora/test.log\", mode=\"w\") as f:\n",
    "    f.write(\"%d\\t%d\\n\"%(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02949478  0.22617405  0.48703183  1.10824636]\n"
     ]
    }
   ],
   "source": [
    "bucket_loss = [0.000869942, 0.0511547, 0.2372, 1.22821]\n",
    "print(np.sqrt(bucket_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
